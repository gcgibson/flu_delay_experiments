\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\BKM@entry[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{WileyNJD-AMA}
\BKM@entry{id=1,open,dest={446F632D5374617274},srcline={65}}{4163636F756E74696E6720666F72205265706F7274696E67205265766973696F6E7320696E20496E666C75656E7A61204461746120696E2074686520556E6974656420537461746573}
\BKM@entry{id=2,open,dest={446F632D5374617274},srcline={65}}{4162737472616374}
\BKM@entry{id=3,open,dest={73656374696F6E2E31},srcline={68}}{496E74726F64756374696F6E}
\BKM@entry{id=4,open,dest={73756273656374696F6E2E312E31},srcline={72}}{496D706F7274616E6365206F6620496E666C75656E7A6120466F726563617374696E67}
\citation{lafond2016global}
\citation{skowronski2018early}
\citation{mylius2008optimal}
\citation{chretien2015advancing}
\citation{cdc}
\citation{kandula2018evaluation}
\citation{biggerstaff2018results}
\citation{dugas2013Influenza}
\citation{araz2014using}
\citation{volkova2017forecasting}
\@writefile{toc}{\contentsline {chapter}{Accounting for Reporting Revisions in Influenza Data in the United States}{1}{Doc-Start}}
\Newlabel{a}{1}
\@writefile{toc}{\contentsline {section}{Abstract}{1}{Doc-Start}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\newlabel{introduction}{{1}{1}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Importance of Influenza Forecasting}{1}{subsection.1.1}}
\newlabel{importance-of-influenza-forecasting}{{1.1}{1}{Importance of Influenza Forecasting}{subsection.1.1}{}}
\citation{reich2019collaborative}
\citation{lawless1994adjustments}
\citation{lampos}
\citation{johansson2014nowcasting}
\citation{kalbfleisch1989inference}
\citation{hohle2014bayesian}
\citation{nunes2013nowcasting}
\citation{stoner2019multivariate}
\citation{osthus2019even}
\citation{lampos}
\BKM@entry{id=5,open,dest={73656374696F6E2E32},srcline={183}}{4D6574686F6473}
\BKM@entry{id=6,open,dest={73756273656374696F6E2E322E31},srcline={186}}{466F726563617374696E67204D6F64656C73}
\@writefile{toc}{\contentsline {section}{\numberline {2}Methods}{2}{section.2}}
\newlabel{methods}{{2}{2}{Methods}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Forecasting Models}{2}{subsection.2.1}}
\newlabel{forecasting-models}{{2.1}{2}{Forecasting Models}{subsection.2.1}{}}
\citation{hohle2014bayesian}
\BKM@entry{id=7,open,dest={73756273656374696F6E2E322E32},srcline={299}}{552E532E20496E666C75656E7A61205375727665696C6C616E63652044617461}
\citation{cdc_flusight}
\BKM@entry{id=8,open,dest={73756273656374696F6E2E322E33},srcline={326}}{5265706F7274696E67207265766973696F6E20726174696F73}
\BKM@entry{id=9,open,dest={73756273756273656374696F6E2E322E332E31},srcline={332}}{4E6F746174696F6E}
\BKM@entry{id=10,open,dest={73756273756273656374696F6E2E322E332E32},srcline={347}}{4D65616E207363616C65207570}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}U.S. Influenza Surveillance Data}{4}{subsection.2.2}}
\newlabel{u.s.-influenza-surveillance-data}{{2.2}{4}{U.S. Influenza Surveillance Data}{subsection.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Reporting revision ratios}{4}{subsection.2.3}}
\newlabel{reporting-revision-ratios}{{2.3}{4}{Reporting revision ratios}{subsection.2.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Notation}{4}{subsubsection.2.3.1}}
\newlabel{notation}{{2.3.1}{4}{Notation}{subsubsection.2.3.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Mean scale up}{4}{subsubsection.2.3.2}}
\newlabel{mean-scale-up}{{2.3.2}{4}{Mean scale up}{subsubsection.2.3.2}{}}
\BKM@entry{id=11,open,dest={73756273756273656374696F6E2E322E332E33},srcline={409}}{53616D706C696E67}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}Sampling}{5}{subsubsection.2.3.3}}
\newlabel{sampling}{{2.3.3}{5}{Sampling}{subsubsection.2.3.3}{}}
\BKM@entry{id=12,open,dest={73756273656374696F6E2E322E34},srcline={476}}{466F726563617374696E67204D6F64656C}
\citation{sarimaTD}
\BKM@entry{id=13,open,dest={73756273656374696F6E2E322E35},srcline={513}}{4576616C756174696F6E}
\BKM@entry{id=14,open,dest={73756273756273656374696F6E2E322E352E31},srcline={516}}{4578706572696D656E74616C207365747570}
\BKM@entry{id=15,open,dest={73756273756273656374696F6E2E322E352E32},srcline={534}}{4D6F64656C2053636F72696E67}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Forecasting Model}{6}{subsection.2.4}}
\newlabel{forecasting-model}{{2.4}{6}{Forecasting Model}{subsection.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Evaluation}{6}{subsection.2.5}}
\newlabel{evaluation}{{2.5}{6}{Evaluation}{subsection.2.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.1}Experimental setup}{6}{subsubsection.2.5.1}}
\newlabel{experimental-setup}{{2.5.1}{6}{Experimental setup}{subsubsection.2.5.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.2}Model Scoring}{6}{subsubsection.2.5.2}}
\newlabel{model-scoring}{{2.5.2}{6}{Model Scoring}{subsubsection.2.5.2}{}}
\BKM@entry{id=16,open,dest={73656374696F6E2E33},srcline={575}}{526573756C7473}
\BKM@entry{id=17,open,dest={73756273656374696F6E2E332E31},srcline={580}}{44617461207265766973696F6E7320757375616C6C7920646F6E2774206D61747465722C20627574207768656E207468657920646F2074686579206861766520612062696720696D70616374}
\citation{diebold2002comparing}
\BKM@entry{id=18,open,dest={73756273656374696F6E2E332E32},srcline={640}}{54686520696D70616374206F66207265706F7274696E67207265766973696F6E7320697320746172676574207370656369666963}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{7}{section.3}}
\newlabel{results}{{3}{7}{Results}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Data revisions usually don't matter, but when they do they have a big impact}{7}{subsection.3.1}}
\newlabel{data-revisions-usually-dont-matter-but-when-they-do-they-have-a-big-impact}{{3.1}{7}{Data revisions usually don't matter, but when they do they have a big impact}{subsection.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}The impact of reporting revisions is target specific}{7}{subsection.3.2}}
\newlabel{the-impact-of-reporting-revisions-is-target-specific}{{3.2}{7}{The impact of reporting revisions is target specific}{subsection.3.2}{}}
\BKM@entry{id=19,open,dest={73756273656374696F6E2E332E33},srcline={677}}{53616D706C696E67206D6574686F642063616E20696D70726F766520666F72656361737420616363757261637920666F7220736561736F6E616C20746172676574732C206275742068757274206F7468657273}
\BKM@entry{id=20,open,dest={73656374696F6E2E34},srcline={721}}{436F6E636C7573696F6E}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Sampling method can improve forecast accuracy for seasonal targets, but hurt others}{8}{subsection.3.3}}
\newlabel{sampling-method-can-improve-forecast-accuracy-for-seasonal-targets-but-hurt-others}{{3.3}{8}{Sampling method can improve forecast accuracy for seasonal targets, but hurt others}{subsection.3.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusion}{8}{section.4}}
\newlabel{conclusion}{{4}{8}{Conclusion}{section.4}{}}
\citation{reich2019collaborative}
\BKM@entry{id=21,open,dest={73656374696F6E2E35},srcline={771}}{417070656E646978}
\@writefile{toc}{\contentsline {section}{\numberline {5}Appendix}{9}{section.5}}
\newlabel{appendix}{{5}{9}{Appendix}{section.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Mean reporting revision: region specific}{9}{section.5}}
\newlabel{mean-reporting-revision-region-specific}{{5}{9}{Mean reporting revision: region specific}{section.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Mean reporting revision: week specific}{9}{section.5}}
\newlabel{mean-reporting-revision-week-specific}{{5}{9}{Mean reporting revision: week specific}{section.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Hierarchical random effects}{9}{section.5}}
\newlabel{hierarchical-random-effects}{{5}{9}{Hierarchical random effects}{section.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Non-linear}{9}{section.5}}
\newlabel{non-linear}{{5}{9}{Non-linear}{section.5}{}}
\BKM@entry{id=22,open,dest={73656374696F6E2E36},srcline={840}}{46696775726573}
\gdef \LT@i {\LT@entry 
    {1}{137.94925pt}\LT@entry 
    {1}{123.65234pt}\LT@entry 
    {1}{103.34769pt}\LT@entry 
    {1}{112.58005pt}}
\bibdata{bib.bib}
\BKM@entry{id=23,open,dest={7461626C652E63617074696F6E2E39},srcline={1}}{5265666572656E636573}
\bibcite{lafond2016global}{{1}{}{{}}{{}}}
\bibcite{skowronski2018early}{{2}{}{{}}{{}}}
\bibcite{mylius2008optimal}{{3}{}{{}}{{}}}
\bibcite{chretien2015advancing}{{4}{}{{}}{{}}}
\bibcite{cdc}{{5}{}{{}}{{}}}
\bibcite{kandula2018evaluation}{{6}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Figures}{10}{section.6}}
\newlabel{figures}{{6}{10}{Figures}{section.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1\kern .5em }{\ignorespaces p-values from Diebold Mariano Test of Difference of Log Score Between Methods. Notice that for almost all 1-4 week ahead targets there is no statistically significant (at .05 level) difference between forecasts made from the revised data and the unrevised data. We also see that on seasonal targets there is a statistically significant difference between the log score of forecasts made from the unrevised data and from the revised data. However, only the sampling method (not the mean scale up method) is able to similarly reject the null that the difference in log score between the methods is 0. We also note that the sampling method is statistically signficiantly different from the unrevised data when forecasting 1-4 week ahead. This means there is a statistically signficant reduction in log score.\relax }}{10}{table.1}}
\@writefile{lot}{\contentsline {table}{\numberline {2\kern .5em }{\ignorespaces Forecast template for a given region $r$ and season $s$, outlining what data is used to forecast each target. \relax }}{10}{table.caption.9}}
\newlabel{tab:my_label}{{2\kern .5em }{10}{Forecast template for a given region $r$ and season $s$, outlining what data is used to forecast each target. \relax }{table.caption.9}{}}
\@writefile{toc}{\contentsline {section}{References\begingroup \let \let \let \let \@unexpandable@protect \xdef {\MakeUppercase  {References}}{\MakeUppercase  {References}}{{\MakeUppercase  {References}}{\MakeUppercase  {References}}}\@temptokena {{\MakeUppercase  {References}}{\MakeUppercase  {References}}}\mark {\thm@preskip 6.0pt\thm@postskip 6.0pt\relax \thm@headfont {\bfseries  }\thm@headpunct {.}}\endgroup }{10}{table.caption.9}}
\bibcite{biggerstaff2018results}{{7}{}{{}}{{}}}
\bibcite{dugas2013Influenza}{{8}{}{{}}{{}}}
\bibcite{araz2014using}{{9}{}{{}}{{}}}
\bibcite{volkova2017forecasting}{{10}{}{{}}{{}}}
\bibcite{reich2019collaborative}{{11}{}{{}}{{}}}
\bibcite{lawless1994adjustments}{{12}{}{{}}{{}}}
\bibcite{lampos}{{13}{}{{}}{{}}}
\bibcite{johansson2014nowcasting}{{14}{}{{}}{{}}}
\bibcite{kalbfleisch1989inference}{{15}{}{{}}{{}}}
\bibcite{hohle2014bayesian}{{16}{}{{}}{{}}}
\bibcite{nunes2013nowcasting}{{17}{}{{}}{{}}}
\bibcite{stoner2019multivariate}{{18}{}{{}}{{}}}
\bibcite{osthus2019even}{{19}{}{{}}{{}}}
\bibcite{cdc_flusight}{{20}{}{{}}{{}}}
\bibcite{sarimaTD}{{21}{}{{}}{{}}}
\bibcite{diebold2002comparing}{{22}{}{{}}{{}}}
\FirstPg{0}\LastPg{10}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\@writefile{lof}{\contentsline {figure}{\numberline {1\kern .5em }{\ignorespaces  A: wILI data from the 2012/2013 and the 2013/2014 season across 4 example regions. Notice the regional variability and the seasonal structure with a peak usually (but not always) occuring somewhere between week 20 and week 30. B: Data from 2013-09-29 (week 1 of the 2013/2014 season) to 2013-12-22 (week 12 of the 2013/2014 season) from HHS region 9. The 'revised' data is a snapshot of wILI values for the listed weeks if the current time is the end of the 2013/2014 season. The 'unrevised' data is a snapshot of wILI values for the listed weeks if the current time were 2013-12-22. Similarly, the lag 5 data is a snapshot of wILI values for the listed weeks if the current time were 5 weeks after 2013-12-22. Notice that unrevised data is both over and under reported relative to the revised data at different epiweeks. Dashed line represents the season onset baseline. \relax }}{12}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:data-overview}{{1\kern .5em }{12}{A: wILI data from the 2012/2013 and the 2013/2014 season across 4 example regions. Notice the regional variability and the seasonal structure with a peak usually (but not always) occuring somewhere between week 20 and week 30. B: Data from 2013-09-29 (week 1 of the 2013/2014 season) to 2013-12-22 (week 12 of the 2013/2014 season) from HHS region 9. The 'revised' data is a snapshot of wILI values for the listed weeks if the current time is the end of the 2013/2014 season. The 'unrevised' data is a snapshot of wILI values for the listed weeks if the current time were 2013-12-22. Similarly, the lag 5 data is a snapshot of wILI values for the listed weeks if the current time were 5 weeks after 2013-12-22. Notice that unrevised data is both over and under reported relative to the revised data at different epiweeks. Dashed line represents the season onset baseline. \relax }{figure.caption.1}{}}
\newlabel{fig:data-overview}{{1\kern .5em }{12}{A: wILI data from the 2012/2013 and the 2013/2014 season across 4 example regions. Notice the regional variability and the seasonal structure with a peak usually (but not always) occuring somewhere between week 20 and week 30. B: Data from 2013-09-29 (week 1 of the 2013/2014 season) to 2013-12-22 (week 12 of the 2013/2014 season) from HHS region 9. The 'revised' data is a snapshot of wILI values for the listed weeks if the current time is the end of the 2013/2014 season. The 'unrevised' data is a snapshot of wILI values for the listed weeks if the current time were 2013-12-22. Similarly, the lag 5 data is a snapshot of wILI values for the listed weeks if the current time were 5 weeks after 2013-12-22. Notice that unrevised data is both over and under reported relative to the revised data at different epiweeks. Dashed line represents the season onset baseline. \relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2\kern .5em }{\ignorespaces Reporting revision ratios broken down by region. The x-axis represents the lag value at discrete intervals. We see that for all regions the revision ratio converges to 1 as the lag increases and that for the most part revision ratios are centered around the currently reported data. \relax }}{13}{figure.caption.2}}
\newlabel{fig:revision-ratios}{{2\kern .5em }{13}{Reporting revision ratios broken down by region. The x-axis represents the lag value at discrete intervals. We see that for all regions the revision ratio converges to 1 as the lag increases and that for the most part revision ratios are centered around the currently reported data. \relax }{figure.caption.2}{}}
\newlabel{fig:revision-ratios}{{2\kern .5em }{13}{Reporting revision ratios broken down by region. The x-axis represents the lag value at discrete intervals. We see that for all regions the revision ratio converges to 1 as the lag increases and that for the most part revision ratios are centered around the currently reported data. \relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3\kern .5em }{\ignorespaces  A. Example of observed data distribution g under the empirical distribution induced by sampling historical reporting revision ratios and applying them to the currently observed data. Notice the uncertainty around the currently observed data as represented by both an 80 and 50 CI around the true observed data. The sampling method is able to put some positive probability on the finally revised data, but remains centered around the currently observed data. B Notation schematic highlighting the cross sections of data used in the experiments. Of primary interest are the three vectors: the set of revised data $\mathaccentV {vec}192{Y}_{4,\infty }$, the most recent set of data $\mathaccentV {vec}192{Y}_{4,l}$ and the initially reported set of data $\mathaccentV {vec}192{Y}_{4,0}$.\relax }}{14}{figure.caption.3}}
\newlabel{fig:notation_and_g}{{3\kern .5em }{14}{A. Example of observed data distribution g under the empirical distribution induced by sampling historical reporting revision ratios and applying them to the currently observed data. Notice the uncertainty around the currently observed data as represented by both an 80 and 50 CI around the true observed data. The sampling method is able to put some positive probability on the finally revised data, but remains centered around the currently observed data. B Notation schematic highlighting the cross sections of data used in the experiments. Of primary interest are the three vectors: the set of revised data $\vec {Y}_{4,\infty }$, the most recent set of data $\vec {Y}_{4,l}$ and the initially reported set of data $\vec {Y}_{4,0}$.\relax }{figure.caption.3}{}}
\newlabel{fig:notation_and_g}{{3\kern .5em }{14}{A. Example of observed data distribution g under the empirical distribution induced by sampling historical reporting revision ratios and applying them to the currently observed data. Notice the uncertainty around the currently observed data as represented by both an 80 and 50 CI around the true observed data. The sampling method is able to put some positive probability on the finally revised data, but remains centered around the currently observed data. B Notation schematic highlighting the cross sections of data used in the experiments. Of primary interest are the three vectors: the set of revised data $\vec {Y}_{4,\infty }$, the most recent set of data $\vec {Y}_{4,l}$ and the initially reported set of data $\vec {Y}_{4,0}$.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4\kern .5em }{\ignorespaces  Log score histograms of the difference in scores between forecasts made from the method noted and forecasts made from the revised data for the season onset target. Mean difference is displayed by the red line. The sampling method is able to remove the tail of the histogram for the season onset target.Histograms are presented with log scaled y-axis. \relax }}{15}{figure.caption.4}}
\newlabel{fig:results}{{4\kern .5em }{15}{Log score histograms of the difference in scores between forecasts made from the method noted and forecasts made from the revised data for the season onset target. Mean difference is displayed by the red line. The sampling method is able to remove the tail of the histogram for the season onset target.Histograms are presented with log scaled y-axis. \relax }{figure.caption.4}{}}
\newlabel{fig:results}{{4\kern .5em }{15}{Log score histograms of the difference in scores between forecasts made from the method noted and forecasts made from the revised data for the season onset target. Mean difference is displayed by the red line. The sampling method is able to remove the tail of the histogram for the season onset target.Histograms are presented with log scaled y-axis. \relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5\kern .5em }{\ignorespaces  Log score histograms of the difference in scores between forecasts made from the method noted and forecasts made from the revised data for the 1 week ahead target. Mean difference is displayed by the red line. There is very little difference between the histograms. Histograms are presented with log scaled y-axis. \relax }}{16}{figure.caption.5}}
\newlabel{fig:results-2}{{5\kern .5em }{16}{Log score histograms of the difference in scores between forecasts made from the method noted and forecasts made from the revised data for the 1 week ahead target. Mean difference is displayed by the red line. There is very little difference between the histograms. Histograms are presented with log scaled y-axis. \relax }{figure.caption.5}{}}
\newlabel{fig:results-2}{{5\kern .5em }{16}{Log score histograms of the difference in scores between forecasts made from the method noted and forecasts made from the revised data for the 1 week ahead target. Mean difference is displayed by the red line. There is very little difference between the histograms. Histograms are presented with log scaled y-axis. \relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6\kern .5em }{\ignorespaces  Log score histograms of the difference in scores between forecasts made from the method noted and forecasts made from the revised data for the peak week percentage. Mean difference is displayed by the red line. There is very little difference between the histograms. Histograms are presented with log scaled y-axis. \relax }}{17}{figure.caption.6}}
\newlabel{fig:results-3}{{6\kern .5em }{17}{Log score histograms of the difference in scores between forecasts made from the method noted and forecasts made from the revised data for the peak week percentage. Mean difference is displayed by the red line. There is very little difference between the histograms. Histograms are presented with log scaled y-axis. \relax }{figure.caption.6}{}}
\newlabel{fig:results-3}{{6\kern .5em }{17}{Log score histograms of the difference in scores between forecasts made from the method noted and forecasts made from the revised data for the peak week percentage. Mean difference is displayed by the red line. There is very little difference between the histograms. Histograms are presented with log scaled y-axis. \relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7\kern .5em }{\ignorespaces  A: By examining the correlation between log score and reporting revisions we see that poor performing 1 week ahead forecasts are not highly correlated with extreme reporting ratios (further from 1). B Relationship between the sample based variance of the initially reported revision ratios over all test seasons and all test regions and the difference in the log score of forecasts based on the revised and the unrevised data. A single point represents a single region and season combination for all test seasons. Notice that as the variance of the reporting ratio decreases so does the difference in the log score, and therefore the room for improvement made by the revision algorithms diminishes. This is expected, as the more revisions occur during a season, the more the revision algorithms would help.\relax }}{18}{figure.caption.7}}
\newlabel{fig:explanations}{{7\kern .5em }{18}{A: By examining the correlation between log score and reporting revisions we see that poor performing 1 week ahead forecasts are not highly correlated with extreme reporting ratios (further from 1). B Relationship between the sample based variance of the initially reported revision ratios over all test seasons and all test regions and the difference in the log score of forecasts based on the revised and the unrevised data. A single point represents a single region and season combination for all test seasons. Notice that as the variance of the reporting ratio decreases so does the difference in the log score, and therefore the room for improvement made by the revision algorithms diminishes. This is expected, as the more revisions occur during a season, the more the revision algorithms would help.\relax }{figure.caption.7}{}}
\newlabel{fig:explanations}{{7\kern .5em }{18}{A: By examining the correlation between log score and reporting revisions we see that poor performing 1 week ahead forecasts are not highly correlated with extreme reporting ratios (further from 1). B Relationship between the sample based variance of the initially reported revision ratios over all test seasons and all test regions and the difference in the log score of forecasts based on the revised and the unrevised data. A single point represents a single region and season combination for all test seasons. Notice that as the variance of the reporting ratio decreases so does the difference in the log score, and therefore the room for improvement made by the revision algorithms diminishes. This is expected, as the more revisions occur during a season, the more the revision algorithms would help.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8\kern .5em }{\ignorespaces A. Example of HHS 2 seasonal target delay using currently reported data as of 2016 week 19 (black) against the fully revised data (blue). Notice that revisions are made to the sesaon onset at week 2016-01 that make initially reported season onset invalid. Similarly, season peak week is initially reported above the true value, so for all epiweeks after 2016-10 the model incorrectly places all denisty on or above the initally reported density. B Difference in log score between forecasts made from unrevised vs revised data for the week ahead targets under both multibin and single bin log scoring rules. We can see that, especially for 1-2 week ahead targets, there is a difference between the two scoring procedures. However, this difference is quite samll on the log score scale, suggesting the scoring rule is not masking the effect of revisions. \relax }}{19}{figure.caption.8}}
\newlabel{fig:season-target-explanation}{{8\kern .5em }{19}{A. Example of HHS 2 seasonal target delay using currently reported data as of 2016 week 19 (black) against the fully revised data (blue). Notice that revisions are made to the sesaon onset at week 2016-01 that make initially reported season onset invalid. Similarly, season peak week is initially reported above the true value, so for all epiweeks after 2016-10 the model incorrectly places all denisty on or above the initally reported density. B Difference in log score between forecasts made from unrevised vs revised data for the week ahead targets under both multibin and single bin log scoring rules. We can see that, especially for 1-2 week ahead targets, there is a difference between the two scoring procedures. However, this difference is quite samll on the log score scale, suggesting the scoring rule is not masking the effect of revisions. \relax }{figure.caption.8}{}}
\newlabel{fig:season-target-explanation}{{8\kern .5em }{19}{A. Example of HHS 2 seasonal target delay using currently reported data as of 2016 week 19 (black) against the fully revised data (blue). Notice that revisions are made to the sesaon onset at week 2016-01 that make initially reported season onset invalid. Similarly, season peak week is initially reported above the true value, so for all epiweeks after 2016-10 the model incorrectly places all denisty on or above the initally reported density. B Difference in log score between forecasts made from unrevised vs revised data for the week ahead targets under both multibin and single bin log scoring rules. We can see that, especially for 1-2 week ahead targets, there is a difference between the two scoring procedures. However, this difference is quite samll on the log score scale, suggesting the scoring rule is not masking the effect of revisions. \relax }{figure.caption.8}{}}
